{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_IDF_from_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dS8BJwWX4GU"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSRJ4KT3OMw"
      },
      "source": [
        "\n",
        "\n",
        "corpus = [\n",
        "     'this is the first document mostly',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document here',\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWI4WuaDvJLz"
      },
      "source": [
        "def ComputeTF(corpus, wordlist):\n",
        "    # formula = No_of_repeatation_of_word_in_a_sentence / No_of_words_in_a_sentence\n",
        "    tf_values =[]\n",
        "    \n",
        "    tf_dict = dict.fromkeys(wordlist, 0)  # Creating dict of words\n",
        "    for sentence in corpus:\n",
        "        tf = {}\n",
        "        list_of_sentence = sentence.split()\n",
        "        length = len(list_of_sentence)    #No_of_words_in_a_sentence\n",
        "        \n",
        "        for key in tf_dict.keys():\n",
        "            count = list_of_sentence.count(key) # counting No_of_repeatation_of_word_in_a_sentence\n",
        "            tf_value = count/length   # calculating term-frequency\n",
        "            tf[key] = (tf_value)\n",
        "        tf_values.append(tf)     # creating list of dictionary \n",
        "\n",
        "    #print(pd.DataFrame(tf_values, columns = [key for key in tf_values[0].keys()]))\n",
        "    return tf_values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMolmwnziyyx"
      },
      "source": [
        "import math\n",
        "def ComputeIDF(tfidf_data, wordlist):\n",
        "\n",
        "  # formula = log (Total_No_of_on_sentence / No_of_sentence_containing_word)\n",
        "\n",
        "    idf = {} # Creating dict for storing idf value of each word\n",
        "    no_of_sentence = len(tfidf_data)  \n",
        "    for key in wordlist:\n",
        "        count = 0               # Counter for counting No_of_sentence_containing_word \n",
        "        for sentence in tfidf_data:\n",
        "            if key in sentence.split():\n",
        "                count += 1\n",
        "        idf[key] = math.log(no_of_sentence/count)\n",
        "    return idf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYoKXNsU3nhO"
      },
      "source": [
        "# Please implement this fucntion and write your code wherever asked. Do NOT change the code snippets provided by us.\n",
        "def computeTFIDF (corpus):\n",
        "  \"\"\"Given a list of sentences as \"corpus\", return the TF-IDF vectors for all the \n",
        "  sentences in the corpus as a numpy 2D matrix. \n",
        "  \n",
        "  Each row of the 2D matrix must correspond to one sentence \n",
        "  and each column corresponds to a word in the text corpus. \n",
        "  \n",
        "  Please order the rows in the same order as the \n",
        "  sentences in the input \"corpus\". \n",
        "    \n",
        "  Ignore puncutation symbols like comma, fullstop, \n",
        "  exclamation, question-mark etc from the input corpus.\n",
        "  \n",
        "  For e.g, If the corpus contains sentences with these \n",
        "  9 distinct words, ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], \n",
        "  then the first column of the 2D matrix will correpsond to word \"and\", the second column will \n",
        "  correspond to column \"document\" and so on. \n",
        "  \n",
        "  Write this function using only basic Python code, inbuilt Data Structures and  NumPy ONLY.\n",
        "\n",
        "  Implement the code as optimally as possible using the inbuilt data structures of Python.\n",
        "  \"\"\"\n",
        "\n",
        "  ##############################################################\n",
        "\n",
        "\n",
        "  wordlist = []\n",
        "  for sentence in corpus:\n",
        "        wordlist.extend(sentence.split())\n",
        "  wordlist = list(set(wordlist))\n",
        "\n",
        "  tf_values = ComputeTF(corpus, wordlist)\n",
        "\n",
        "  idf = ComputeIDF(corpus, wordlist)\n",
        "\n",
        "###############################################################\n",
        "\n",
        "  tfidf = []\n",
        "  idf_val = np.array(list(idf.values()))\n",
        "  for i in range(len(tf_values)):\n",
        "    tf = np.array(list(tf_values[i].values()))\n",
        "    tfidf.append(tf*idf_val)\n",
        "  #print(pd.DataFrame(np.array(tfidf), columns = wordlist))\n",
        "  tfidf_value = np.array(tfidf)\n",
        "\n",
        "###############################################################\n",
        "\n",
        "  final_array = []\n",
        "  i = 0\n",
        "  for sentence in corpus:\n",
        "    temp = []\n",
        "    for word in sentence.split():\n",
        "      index = wordlist.index(word)\n",
        "      temp.append(round(tfidf_value[i][index],2))\n",
        "    i += 1\n",
        "    final_array.append(temp)\n",
        "\n",
        "  return final_array\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ_hmMn92bEe"
      },
      "source": [
        "# Grader Cell\n",
        "Please execute the following Grader cell to verify the correctness of your above implementation. This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct, else, it will print \"Failed\". Make sure you get a \"Success\" before you submit the code in the classroom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUYmXFjfu53i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c59f553-de41-4c91-b665-d7f2534619ed"
      },
      "source": [
        "###########################################\n",
        "## GRADER CELL: Do NOT Change this.\n",
        "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
        "# Else, it will print \"Failed\"\n",
        "###########################################\n",
        "import numpy as np\n",
        "\n",
        "# compute TF-IDF using the computeTFIDF() function\n",
        "X_custom = computeTFIDF(corpus)\n",
        "\n",
        "# Reference grader array - DO NOT MODIFY IT\n",
        "X_grader = np.array(\n",
        "    [[0, 0, 0, 0.12, 0.05, 0.23],\n",
        "     [0, 0.1, 0, 0, 0.23, 0.1],\n",
        "     [0.23, 0, 0, 0, 0.23, 0.23],\n",
        "     [0, 0, 0, 0.12, 0.05, 0.23]]\n",
        "     )\n",
        "\n",
        "# compare X_grader and X_custom\n",
        "comparison = ( X_grader == X_custom )\n",
        "isEqual = comparison.all()\n",
        "\n",
        "if isEqual:\n",
        "  print(\"******** Success ********\")\n",
        "else:\n",
        "  print(\"####### Failed #######\")\n",
        "  print(\"\\nX_grader = \\n\\n\", X_grader)\n",
        "  print(\"\\n\",\"*\"*50)\n",
        "  print(\"\\nX_custom = \\n\\n\", X_custom)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******** Success ********\n"
          ]
        }
      ]
    }
  ]
}