{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAlENnFPpQ3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ecddda-934d-4dd0-d3fe-5e8a5450c3a5"
      },
      "source": [
        "# Code to mount google drive in case you are loading the data from your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/Colab Notebooks/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMnahnQEpfQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "8f3e39a9-b2be-4973-8f62-2c3c9a25113a"
      },
      "source": [
        "# Loading data from csv file\n",
        "import pandas as pd\n",
        "data_path = 'logistic_regression_assignment_data.csv'\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>0</td>\n",
              "      <td>wall street cool to ebay s profit shares in on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>0</td>\n",
              "      <td>ban on forced retirement under 65 employers wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>1</td>\n",
              "      <td>time to get tough on friendlies  for an intern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>0</td>\n",
              "      <td>christmas shoppers flock to tills shops all ov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>0</td>\n",
              "      <td>bush budget seeks deep cutbacks president bush...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1017 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      category                                               text\n",
              "0            0  worldcom boss  left books alone  former worldc...\n",
              "1            1  tigers wary of farrell  gamble  leicester say ...\n",
              "2            1  yeading face newcastle in fa cup premiership s...\n",
              "3            1  henman hopes ended in dubai third seed tim hen...\n",
              "4            1  wilkinson fit to face edinburgh england captai...\n",
              "...        ...                                                ...\n",
              "1012         0  wall street cool to ebay s profit shares in on...\n",
              "1013         0  ban on forced retirement under 65 employers wi...\n",
              "1014         1  time to get tough on friendlies  for an intern...\n",
              "1015         0  christmas shoppers flock to tills shops all ov...\n",
              "1016         0  bush budget seeks deep cutbacks president bush...\n",
              "\n",
              "[1017 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTQOrw6JCu5D"
      },
      "source": [
        "#### **Note:** Here class-0 is of category \"business\" and class-1 is of category \"sport\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0_a8GvRqwzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca046e4-cf88-47c4-f2ec-0e798c3840a8"
      },
      "source": [
        "# Data Overiview\n",
        "df['category'].value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    509\n",
              "0    508\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW3eJmVbubx4"
      },
      "source": [
        "### Creating Train and Test Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5iXh7PusnyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c517582-40ca-47c1-f0ac-d21f08f3afa0"
      },
      "source": [
        "# Splitting the data into train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "text = df['text']\n",
        "category = df['category']\n",
        "train_text, test_text, train_category, test_category = train_test_split(text, category, random_state=42, stratify=category, test_size=0.01)\n",
        "\n",
        "print(\"Shape of Train_Text = \", train_text.shape)\n",
        "print(\"Shape of Test_Text = \", test_text.shape)\n",
        "print(\"Shape of Train_Category = \", train_category.shape)\n",
        "print(\"Shape of Train_Category = \", test_category.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train_Text =  (1006,)\n",
            "Shape of Test_Text =  (11,)\n",
            "Shape of Train_Category =  (1006,)\n",
            "Shape of Train_Category =  (11,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n2JoKcm1xqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ffed20-bd34-415c-ed83-9e72c0e6b82f"
      },
      "source": [
        "train_text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "381    china keeps tight rein on credit china s effor...\n",
              "313    davenport puts retirement on hold lindsay dave...\n",
              "978    boeing secures giant japan order boeing is to ...\n",
              "726    wenger signs new deal arsenal manager arsene w...\n",
              "720    bath faced with tindall ultimatum mike tindall...\n",
              "                             ...                        \n",
              "249    kerr frustrated at victory margin republic of ...\n",
              "438    umaga ready for  fearsome  lions all blacks ca...\n",
              "210    s korea spending boost to economy south korea ...\n",
              "255    brazil buy boosts belgium s inbev belgian brew...\n",
              "823    english clubs make euro history all four of en...\n",
              "Name: text, Length: 1006, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6JlCeWPvNPS"
      },
      "source": [
        "## Custom Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kb2V8ZXM-6M"
      },
      "source": [
        "###Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Zm11bHNGBi"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hfDStz1LvEe"
      },
      "source": [
        "### 1. Vectorize train data and test data using sklearn tf-idf in the below cell\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoiLZawBMI2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12251934-bb33-494b-f5f4-ea3a3325864f"
      },
      "source": [
        "'''vectorize train and test data using TF-IDF and store them in train_vectors and test_vectors respectively'''\n",
        "tf = TfidfVectorizer(ngram_range=(2,3), max_features=2000, min_df = 10)\n",
        "train_vectors = tf.fit_transform(train_text)\n",
        "test_vectors = tf.transform(test_text)\n",
        "train_vectors.shape, test_vectors.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1006, 2000), (11, 2000))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0igVcuTSN4pS"
      },
      "source": [
        "###2. Column standardize the train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9vQGIN_N8u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef73530-6903-4ce7-a0f5-b2eb56c6b188"
      },
      "source": [
        "'''column standardize the train and test data and store them in train_vectors_stand and test_vectors_stand'''\n",
        "\n",
        "sc = StandardScaler()\n",
        "#sc_fit = sc.fit(train_vectors)\n",
        "train_vectors_stand = sc.fit_transform(train_vectors.toarray())\n",
        "test_vectors_stand = sc.transform(test_vectors.toarray())\n",
        "train_vectors_stand.shape, test_vectors_stand.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1006, 2000), (11, 2000))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKL7ul-A5U6n"
      },
      "source": [
        "### 3. Custom function to intialise your weights and bias terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUmNAPWe3rso"
      },
      "source": [
        "def initialize_weights_bias(dim):\n",
        "    ''' In this function, we will initialize our weights and bias terms'''\n",
        "\n",
        "    # Initialize the weights to zeros array of (dim) dimensions. Here dim will be the number of features of your tfidf vectorizer output.\n",
        "    # You can initialize the weight terms with zeros.\n",
        "    # Initialize bias term to zero\n",
        "    # Write your code below.\n",
        "\n",
        "    w = np.zeros(shape = dim)\n",
        "    b=0\n",
        "\n",
        "    return w,b"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLGMaOFE6JDF"
      },
      "source": [
        "### 4. Custom function to calculate sigmoid of a value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfP2Z7gv3JpX"
      },
      "source": [
        "import math\n",
        "def custom_sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    \n",
        "    # Compute sigmoid(z) and return its value.\n",
        "    # Write your code below .\n",
        "    sigmoid = 1/(1+np.exp(-z))\n",
        "\n",
        "    return sigmoid"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO8O987t0tz7",
        "outputId": "291864a8-2606-43a6-b37c-4cae4f8b2c09"
      },
      "source": [
        "custom_sigmoid(np.ones(train_vectors_stand.shape[1])*train_vectors_stand[0]+ 0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.46555713, 0.46364171, 0.47533448, ..., 0.45351281, 0.45514662,\n",
              "       0.46460368])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVTM6TpQ6JTS"
      },
      "source": [
        "### 5.  Custom function to compute loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5B5oKpf4h0n"
      },
      "source": [
        "$logloss = -1*\\frac{1}{n}\\Sigma_{for each Y_{true},Y_{pred}}(Y_{true}log10(Y_{pred})+(1-Y_{true})log10(1-Y_{pred}))$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnS1uSrV6CAk"
      },
      "source": [
        "$L1 loss = \\Sigma_{for each w}(|w|)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azcvxO3u6lNK"
      },
      "source": [
        "$total loss = logloss + alpha*L1loss$<br>\n",
        "Where alphas is the regularization parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41ush74x8ueR"
      },
      "source": [
        "def custom_loss(y_true, y_pred, alpha, w):\n",
        "    '''In this function, we will compute total loss which is [(logloss) + (alpha * L1regularization loss)] '''\n",
        "    \n",
        "    # Write your code below.\n",
        "    result = 0\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    result = np.sum((y_true*np.log10(y_pred)) + (1-y_true)*np.log10(1-y_pred))\n",
        "    #print(result)\n",
        "\n",
        "    log_loss = (-1)*(1/len(y_true))*result\n",
        "    #print(log_loss)\n",
        "    l1_loss = np.sum(np.abs(w))\n",
        "    #print(l1_loss)\n",
        "    #print(total_loss)\n",
        "    return log_loss + alpha*l1_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQGM1j2B6Jbf"
      },
      "source": [
        "### 6. Custom function to updated weights and bias terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlqoG2CBMAjI"
      },
      "source": [
        "Use the below formula to compute gradient of your weight and bias terms <br>\n",
        "Loss term Li for a single example is given as below: \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "$Li= -(Y_{i}log10(𝝈_{i})-(1-Y_{i})log10(1-𝝈_{i}) + \\frac{alpha}{N}(sum(|w|))\n",
        "$ <br>\n",
        "<br>\n",
        "$Where: 𝝈_{i} = σ(w^{T} x_i+b) $ <br>\n",
        "<br>\n",
        "And: L1 regularization = $\\frac{alpha}{N}(sum(|w|)) $ <br>\n",
        "Alpha: It is the Regularization parameter <br>\n",
        "N : number of training examples<br>\n",
        "σ : sigmoid function <br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "$dLi/dw= -Y_{i}x_{i}(1-𝝈_{i}) + (1-Y_{i})x_{i}𝝈_{i} + \\frac{w + (1e-5)}{|w + (1e-5)|}  $<br>\n",
        "NOTE THAT: 1e-5 used in numerator and denominator to avoid division error <br>\n",
        "\n",
        "$dLi/db= -Y_{i}(1-𝝈_{i}) + (1-Y_{i})𝝈_{i}$<br>\n",
        "<br>\n",
        "<br>\n",
        "Hence,<br>\n",
        "$dLi/dw= dw = (𝝈_{i} -Y_{i})x_{i} + \\frac{alpha}{N}\\frac{w + (1e-5)}{|w + (1e-5)|} $<br>\n",
        "1e-5 used in numerator and denominator to avoid division error <br>\n",
        "$dLi/db =  db = 𝝈_{i}-Y_{i}$\n",
        "<br>\n",
        "<br>\n",
        "!!NOTE: USE NEGATIVE GRADIENT WHILE UPDATING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UBBkZNJM2Fg"
      },
      "source": [
        "### 6a. Custom function to compute Gradient of loss function wrt weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hREi7bQxM8h-"
      },
      "source": [
        "def gradient_dw(x, y, w, b, alpha, N):\n",
        "    '''In this function, we will compute the gardient w.r.t. w '''\n",
        "    # Write your code below.\n",
        "    a = (np.array(custom_sigmoid(np.dot(w, x) + b)) - y)*x\n",
        "    b = np.array((alpha/N)*((w+1e-5))/abs(w+1e-5))\n",
        "    dw = a+b\n",
        "    return dw"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeJFno3n5Ef_",
        "outputId": "af9652b8-8f79-4792-d637-8188b0817aa1"
      },
      "source": [
        "gradient_dw(train_vectors_stand[0], train_category[0],np.ones(train_vectors_stand.shape[1]), 0, 0.1, 2000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.13792478, -0.14562423, -0.09868135, ..., -0.18641679,\n",
              "       -0.17982729, -0.14175686])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyxGabPPM_lL"
      },
      "source": [
        "### 6b.  Custom function to compute Gradient of loss function wrt bias term:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIMxwuBAND0a"
      },
      "source": [
        "def gradient_db(x, y, w, b):\n",
        "    '''In this function, we will compute the gardient w.r.t. b '''\n",
        "    # dLi/db=db=σi−Yi\n",
        "    # Write your code below.\n",
        "    db = custom_sigmoid(np.dot(w, x.T) + b) - y\n",
        "\n",
        "    return db"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWEdXySI5YA8",
        "outputId": "9da53fb9-a1b4-439b-da4b-3125ffd15961"
      },
      "source": [
        "gradient_db(train_vectors_stand[0], train_category[0],np.ones(train_vectors_stand.shape[1]), 0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9998896481246118"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA6UuRWA-Pvf"
      },
      "source": [
        "###6c. Custom function to train logistic regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgdgYdyRX06U"
      },
      "source": [
        "$w^{(t+1)}← w^{(t)}- eta0*(dw^{(t)}) $<br>\n",
        "$b^{(t+1)}←b^{(t)} - eta0*(db^{(t)}) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44nod2Gu-ZWq"
      },
      "source": [
        "def custom_train(X_train, y_train,alpha, eta0,tolerance):\n",
        "  \"\"\"\n",
        "  In this function we will compute optimal values for weights and bias terms on\n",
        "  the train data. \n",
        "\n",
        "  Here eta0 is the learning rate and alpha is the regularization term.\n",
        "  \"\"\"\n",
        "  train_loss=[]\n",
        "\n",
        "  # Implement the code as follows:\n",
        "\n",
        "  # 1. Initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "  w, b = initialize_weights_bias(X_train.shape[1])\n",
        "  # 2. Repeat For many epochs until condition \"e\"  fails\n",
        "          # a) for every data point(X_train,y_train)\n",
        "                # compute gradient w.r.to w (call the gradient_dw() function)\n",
        "                # compute gradient w.r.to b (call the gradient_db() function)\n",
        "                # update w, b using the above eqns\n",
        "          # b) predict the output of x_train[for all data points in X_train] using w,b\n",
        "          # c) compute the loss between predicted and actual values (call the loss function)\n",
        "          # d) store all the train loss values in a list\n",
        "          # e) Compare previous loss and current loss, if the difference between loss is not more than or equal to the tolerance, stop the process and return w,b\n",
        "  N = len(X_train)\n",
        "  #print(N)\n",
        "  condition = True\n",
        "  counter = 0\n",
        "  while(condition):\n",
        "    \n",
        "    # Computing Gradient\n",
        "    for i in range (len(X_train)):\n",
        "      dw = gradient_dw(X_train[i], y_train[i], w, b, alpha, N)\n",
        "      db = gradient_db(X_train[i], y_train[i], w, b)\n",
        "      # Updating gradient\n",
        "      w = w - eta0*dw\n",
        "      b = b - eta0*db\n",
        "\n",
        "    #print(w.shape)\n",
        "    y_pred = []\n",
        "\n",
        "    for train in X_train:\n",
        "      y_pred.append(custom_sigmoid(np.dot(w,train)+b))      # Predicting value for X train\n",
        "\n",
        "    train_loss.append(custom_loss(y_train, y_pred, alpha, w))   #  Computing loss with each iteration\n",
        "\n",
        "    # If differene in loss is then tolerance then stop the loop\n",
        "    if counter>=1:\n",
        "      if train_loss[counter-1] - train_loss[counter] <= tolerance:\n",
        "        condition = False\n",
        "    counter += 1\n",
        "  # 3. Return the values of weights, bias, train_loss and num_epochs \n",
        "  \n",
        "  return w,b,train_loss,counter\n",
        "  #return w,b,train_loss,num_epochs\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6nCLdiidV0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ed4806-c2c8-473f-ff2a-942f4a7e5963"
      },
      "source": [
        "w,b,train_loss,epoch = custom_train(train_vectors_stand, train_category.values, 0.0001,0.0001,0.001)\n",
        "epoch"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHrNKvsemncP"
      },
      "source": [
        "### 7. Plot the train loss with x as epoch number and y as train loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ_7XOwzmvvi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "38dba8e5-2d8e-45ac-a44e-334634ba7d92"
      },
      "source": [
        "# plotting graph for epoch vs loss for train and test data\n",
        "\n",
        "w,b,train_loss,epochs = custom_train(train_vectors_stand, train_category.values, 0.0001,0.0001,0.001)\n",
        "plt.plot(range(epochs),train_loss,label='train curve')\n",
        "plt.title('epoch vs loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYy8iqhrAne2"
      },
      "source": [
        "### 8. Custom function to make predictions using logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2gy5NvAlC_6"
      },
      "source": [
        "def predict(w,b, X):\n",
        "    '''function to predict label given weights, bias and standardized data'''\n",
        "    X_len = len(X)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(X_len):\n",
        "      sigma_value = custom_sigmoid(np.dot(w,X[i]) + b)\n",
        "\n",
        "      predictions.append(1) if sigma_value >= 0.5 else predictions.append(0)\n",
        "        \n",
        "\n",
        "    return predictions #it should be a numpy array"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY3E_yv2OGiD"
      },
      "source": [
        "### Grader Function - 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKYawSBtlRD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42ac726-e46d-40d8-84c4-9d407b254410"
      },
      "source": [
        "def grader_predict():\n",
        "  ''' grader to check the test accuracy'''\n",
        "  w,b,_,_ = custom_train(train_vectors_stand, train_category.values, 0.0001,0.0001,0.001)\n",
        "  test_preds= predict(w,b,test_vectors_stand)\n",
        "  test_accuracy= (np.sum(test_category==test_preds)/len(test_preds))*100\n",
        "  if(test_accuracy>=90):\n",
        "    print(\"Success! \")\n",
        "  else:\n",
        "    print(\"Failed! \\n Test accuracy = \", test_accuracy)\n",
        "  return\n",
        "  \n",
        "grader_predict()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! \n"
          ]
        }
      ]
    }
  ]
}